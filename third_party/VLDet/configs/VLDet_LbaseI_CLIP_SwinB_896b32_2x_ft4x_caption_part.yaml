_BASE_: "Base-C2_L_R5021k_640b64_4x.yaml"
MODEL:
  WITH_CAPTION: True
  ROI_HEADS:
    NUM_CLASSES: 81
  ROI_BOX_HEAD:
    ADD_IMAGE_BOX: True
    USE_ZEROSHOT_CLS: True
    WS_NUM_PROPS: 5
    USE_OT: 'contrastive'
    OT_LOSS_WEIGHT: 0.05
    USE_CAPTION: True
    CAPTION_WEIGHT: 1.0
    ZEROSHOT_WEIGHT_PATH: 'datasets/pascal_part_clip_a+cname.pth'
    DETECTION_WEIGHT_PATH: 'datasets/pascal_part_clip_a+cname.pth'
    ZEROSHOT_WEIGHT_DIM: 1024
    USE_FED_LOSS: False # inference only
    IGNORE_ZERO_CATS: False # inference only
  SHARE_PROJ_V_DIM: 1024
  SHARE_PROJ_L_DIM: 1024
  BACKBONE:
    NAME: build_swintransformer_fpn_backbone
  SWIN:
    SIZE: B-22k
  FPN:
    IN_FEATURES: ["swin1", "swin2", "swin3"]
  WEIGHTS: "models/lvis_base_swinB.pth"
SOLVER:
  MAX_ITER: 90000
  IMS_PER_BATCH: 32
  BASE_LR: 0.0001
  WARMUP_ITERS: 1000
  WARMUP_FACTOR: 0.001
DATASETS:
  TRAIN: ("lvis_v1_train_norare", "cc3m_v1_nouns_train_6250tags")
  TEST: ("pascal_part_val",)
DATALOADER:
  SAMPLER_TRAIN: "MultiDatasetSampler"
  DATASET_RATIO: [1, 4]
  USE_DIFF_BS_SIZE: True
  DATASET_BS: [4, 16]
  DATASET_INPUT_SIZE: [896, 448]
  USE_RFS: [True, False]
  DATASET_INPUT_SCALE: [[0.1, 2.0], [0.5, 1.5]]
  FILTER_EMPTY_ANNOTATIONS: False
  MULTI_DATASET_GROUPING: True
  DATASET_ANN: ['box', 'caption']
  NUM_WORKERS: 8
WITH_IMAGE_LABELS: True
OUTPUT_DIR: output/lvis_swinB
